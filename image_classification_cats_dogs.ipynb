{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f6094aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "# PIL -visulization tools,Image-read/write, ImageTK-user interface\n",
    "from PIL import Image, ImageTk\n",
    "#bit-bytes problem solve; encoding to decoding, hexa-decimal\n",
    "from io import BytesIO\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# requests for client/user\n",
    "import requests\n",
    "#Tk-user interface, Canvas-Area, Label-image seting position, NW-calling image\n",
    "from tkinter import Tk, Label, Canvas, Entry, Button, NW\n",
    "\n",
    "\n",
    "#load_model: save model then load model\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "\n",
    "# image layers, dense-fully connected, Conv2D-Basic 2D CNN, Flatten-Create bridge\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "# text for NLP, load_img, img_to_array-convert image to array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "#image_utils-image raw processing\n",
    "from tensorflow.keras.preprocessing import image as image_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63f4d175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 15:21:35.251934: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-11-30 15:21:35.252041: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# empty space creat\n",
    "model = Sequential()\n",
    "\n",
    "#input layer,Conv2D-create layer for image,  32-number of node, (3,3)-kernel size,input_shape-RGB image(width, height, color)\n",
    "model.add(Conv2D(32, (3, 3), input_shape = (128, 128, 3), activation = \"relu\"))\n",
    "#parameters: MaxPooling2D:pool_size =(2,2)-\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "#Hidden layer, 64-node assending order of input layer node\n",
    "model.add(Conv2D(64, (3, 3), activation = \"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation = \"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# create the bridge by Flatten\n",
    "model.add(Flatten())\n",
    "\n",
    "#When we will create bridge layer, we don't connect with output layer directly; node should be same with previous layer\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "#Output layer: softmax-more than 2 output\n",
    "model.add(Dense(2, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b699a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile optimizer, loss function, metrics for accuracy\n",
    "model.compile(optimizer=\"adam\",\n",
    "             loss = \"categorical_crossentropy\",\n",
    "             metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96f4db0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data process: rescale image:convert grey image from RGB, shear_range: shape position change by angle wise like image augmentation,zoom_range: zooming data,horizontal_flip: horizontal/vertical_flip  \n",
    "train_datagen = ImageDataGenerator(rescale = 1.0/255,\n",
    "                                  shear_range = 0.2,\n",
    "                                  zoom_range = 0.2,\n",
    "                                  horizontal_flip= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e630d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data process\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92300109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8005 images belonging to 2 classes.\n",
      "Found 2023 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#flow_from_directory: dataset location, target size:unknown size, maximum size, batch size: relation with validation split and total number of size,class_mode:categorical\n",
    "training_datasets = train_datagen.flow_from_directory(\"dataset_cats/training_set/training_set/\", target_size= (128, 128), batch_size = 32, class_mode = \"categorical\")\n",
    "testing_datasets = test_datagen.flow_from_directory(\"dataset_cats/test_set/test_set/\", target_size=(128, 128), batch_size=32, class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6585b8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 15:21:35.857034: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-30 15:21:35.857154: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-11-30 15:21:35.988374: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "126/125 [==============================] - ETA: 0s - loss: 0.6897 - accuracy: 0.5375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 15:21:48.600234: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 14s 111ms/step - loss: 0.6897 - accuracy: 0.5375 - val_loss: 0.6761 - val_accuracy: 0.5605\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 14s 109ms/step - loss: 0.6530 - accuracy: 0.6079 - val_loss: 0.6669 - val_accuracy: 0.6221\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 14s 109ms/step - loss: 0.6320 - accuracy: 0.6340 - val_loss: 0.6674 - val_accuracy: 0.5986\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 14s 108ms/step - loss: 0.6036 - accuracy: 0.6757 - val_loss: 0.5671 - val_accuracy: 0.7188\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 14s 108ms/step - loss: 0.5738 - accuracy: 0.6957 - val_loss: 0.5496 - val_accuracy: 0.7197\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 14s 109ms/step - loss: 0.5608 - accuracy: 0.7166 - val_loss: 0.5288 - val_accuracy: 0.7432\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 14s 111ms/step - loss: 0.5357 - accuracy: 0.7363 - val_loss: 0.5085 - val_accuracy: 0.7510\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 14s 109ms/step - loss: 0.5076 - accuracy: 0.7488 - val_loss: 0.4684 - val_accuracy: 0.7803\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 14s 108ms/step - loss: 0.4834 - accuracy: 0.7661 - val_loss: 0.4919 - val_accuracy: 0.7676\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 14s 108ms/step - loss: 0.4829 - accuracy: 0.7625 - val_loss: 0.4626 - val_accuracy: 0.7686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x179cdee20>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model. steps_per_epoch: total=2400/3=800, 32-batch, spochs=50, validation_steps=total number of images/3(classes)=200\n",
    "model.fit(training_datasets, steps_per_epoch=4002/32, epochs=10, validation_data=testing_datasets,validation_steps =  1010/32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3df4a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "model.save(\"model_cats/model.h5\")\n",
    "model.save_weights(\"model_cats/model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cbb5554",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "image_width, image_height = 128, 128\n",
    "#create the model\n",
    "model_path = \"model_cats/model.h5\"\n",
    "#create model for weight\n",
    "model_wight_path = \"model_cats/model_weights.h5\"\n",
    "\n",
    "final_model = load_model(model_path) \n",
    "final_model.load_weights(model_wight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15e037b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=''\n",
    "window=Tk()\n",
    "window.title(\"Image classification using CNN\")#plt.title()\n",
    "window.geometry(\"800x800\")\n",
    "label = Label(window,text=\"Please Enter your Custom URL\",font=(\"Halvetica\",16))\n",
    "label.pack()\n",
    "\n",
    "def Enter():\n",
    "    global url\n",
    "    label.configure()#why\n",
    "    url=(User_input.get())\n",
    "    print(url)\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    test_image=Image.open(BytesIO(response.content))\n",
    "    put_image=test_image.resize((400,400))#source image\n",
    "    test_image=test_image.resize((128,128))\n",
    "\n",
    "    img = ImageTk.PhotoImage(put_image)\n",
    "    pic = Label(image=img)\n",
    "    pic.pack()# merge the image\n",
    "\n",
    "    pic.image=img\n",
    "    test_image=image_utils.img_to_array(test_image)\n",
    "    test_image= np.expand_dims(test_image,axis=0)\n",
    "\n",
    "    results= final_model.predict_on_batch(test_image)\n",
    "\n",
    "    if results[0][0]==1:\n",
    "        res=\"cats\"\n",
    "    elif results[0][1]==1:\n",
    "        res=\"dogs\"\n",
    "\n",
    "    output= Label(window,text= \"Predicted Results:\"+res,font=(\"Halvetica\",16))\n",
    "    output.pack()\n",
    "    #window.mainloop()\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccb9492b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://learnwebcode.com/images/lessons/insert-image-funny-dog.jpg\n",
      "dogs\n"
     ]
    }
   ],
   "source": [
    "User_input=Entry()\n",
    "User_input.pack()\n",
    "button=Button(window,text=\"Detect Image\",font=(\"Halvetica\",16),command=Enter)\n",
    "button.pack()\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b03a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f95b90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
